# DataCo Supply Chain -- Data Warehouse & Business Intelligence

## ğŸ“‹ Contexte

Projet de systÃ¨me dÃ©cisionnel complet basÃ© sur le dataset **DataCo Supply Chain** (e-commerce international multi-marchÃ©s). \

**Lien vers le dataset** :\
https://www.kaggle.com/datasets/saicharankomati/dataco-supply-chain-dataset\

**Objectif** : Construire un Data Warehouse en Ã©toile + pipeline ETL + dashboards Power BI pour analyserâ€¯: 
- Ventes et rentabilitÃ©\
- Clients et segments\
- Produits et catÃ©gories\
- Performance logistique (dÃ©lais, retards)\
- Analyse temporelle (tendances, saisonnalitÃ©)

------------------------------------------------------------------------

## ğŸ—ï¸ Architecture du projet

``` text
Supply_Chain_ETL_DW_Power_BI/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # Fichiers sources (CSV Kaggle, non versionnÃ©s)
â”‚   â””â”€â”€ processed/                 # Dimensions & fact gÃ©nÃ©rÃ©es par lâ€™ETL
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_etl_dataco_exploration.ipynb   # EDA + construction ETL pas Ã  pas
â”œâ”€â”€ etl/
â”‚   â””â”€â”€ etl_dataco.py              # Pipeline ETL rejouable (pandas)
â”œâ”€â”€ sql/
â”‚   â””â”€â”€ create_tables_dw.sql       # CrÃ©ation des tables DW (schÃ©ma en Ã©toile)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ data_dictionary_etl_rules.md   # Dictionnaire + rÃ¨gles ETL / mapping
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ dataco_powerbi.pbix        # Dashboards Power BI (exemple de rapport)
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

Les fichiers CSV bruts de Kaggle sont attendus dans **data/raw/** mais ne
sont pas obligatoirement dans le repo GitHub (Ã  tÃ©lÃ©charger depuis
Kaggle). \

Les CSV de **data/processed/** sont gÃ©nÃ©rÃ©s par le script ETL et servent de
source au Data Warehouse PostgreSQL. \

## ğŸ“Š ModÃ¨le de donnÃ©es (schÃ©ma en Ã©toile)

### Table de faits

**fact_orders**

Grain : ligne de commande (order item). \

**ClÃ©s** : 
- **order_item_id** (PK technique) 
- **order_id (commande)** 
- **customer_id** (FK â†’ dim_customer) 
- **product_id** (FK â†’ dim_product) 
- **date_id** (FK â†’ dim_time)

**Mesures principales** : 
- **quantity**, **unit_price**, **line_total**, **sales** - **order_benefit**, **order_profit** 
- **days_shipping_real**, **days_shipping_sched**, **delay_days** 
- **margin_ratio**

### Dimensions

Les volumes ci-dessous sont donnÃ©s Ã  titre indicatif pour ce dataset
DataCo. \

**dim_time** 
- ClÃ© : **date_id** (format AAAAMMJJ) 
- Attributs : **order_date**, **year**, **month, day**

**dim_customer** 
- ClÃ© : **customer_id** 
- Attributs : **fname**, **lname**, **segment**, **country**, **city**, **state**, **street**, **zipcode**

**dim_product** 
- ClÃ© : **product_id** 
- Attributs : **product_name**, **category_id**, **category_name**, **department_id**, **department_name**, **product_category_id**, **base_price**

**dim_location** 
- ClÃ© : **location_id** 
- Attributs (cÃ´tÃ© commande) : **order_city**, **order_region**, **market**, **latitude**, **longitude**

**dim_shipping** 
- ClÃ© : **shipping_id**
- Attributs : **shipping_mode**,  **delivery_status**, **late_delivery_risk**

## ğŸš€ Installation et utilisation

### 1. Cloner le projet

``` bash
git clone https://github.com/lattifhayatt2004-ai/dataco-supply-chain-dw.git
cd dataco-supply-chain-dw
```

### 2. Installer les dÃ©pendances Python

``` bash
python -m venv .venv
# Linux / macOS
source .venv/bin/activate
# Windows
# .venv\Scripts\activate

pip install -r requirements.txt
```

### 3. TÃ©lÃ©charger et placer les fichiers sources

#### 3.1. TÃ©lÃ©charger depuis Kaggle :
 **DataCo Supply Chain Dataset**. \

#### 3.2 Placer les fichiers dans **data/raw/** : 
- **DataCoSupplyChainDataset.csv**
- **DescriptionDataCoSupplyChain.csv** (optionnel, utilisÃ© pour la documentation)

### 4. ExÃ©cuter le pipeline ETL

Depuis la racine du projetâ€¯:

``` bash
python etl/etl_dataco.py
```

Cela gÃ©nÃ¨re les fichiers suivants dans data/processed/ :
- **dim_customer.csv** 
- **dim_product.csv** 
- **dim_time.csv** 
- **dim_location.csv** 
- **dim_shipping.csv** 
- **fact_orders.csv**

### 5. CrÃ©er le Data Warehouse PostgreSQL

#### 5.1 CrÃ©er la base : 

``` sql
CREATE DATABASE dataco_dw;
```

#### 5.2 ExÃ©cuter le script de crÃ©ation du schÃ©ma (tables DW)â€¯:

``` sql
\i sql/create_tables_dw.sql
```

#### 5.3 Importer les CSV data/processed/ dans les tables correspondantes :
viapgAdmin : Import/Export Data sur chaque table, en mode CSV, sÃ©parateur ',', header activÃ©. \

#### Remarque : 
un script d'exemple de chargement via **`\copy `** peut Ãªtre ajoutÃ© ultÃ©rieurement, mais l'utilisation de l'outil d'import pgAdmin est la mÃ©thode recommandÃ©e dans ce projet.

### 6. Utiliser les dashboards Power BI

- Ouvrir **reports/dataco_powerbi.pbix** dans **Power BI Desktop**.\

- Ou crÃ©er un nouveau rapport en se connectant Ã  PostgreSQL : 
- - Get Data â†’ PostgreSQL database
- - Server : **localhost** (ou ton serveur)\
- - Database : **dataco_dw**
- - SÃ©lectionner : **dim_time**, **dim_customer**, **dim_product**, **dim_location**, **dim_shipping**, **fact_orders**
- - VÃ©rifier les relations (notamment les FK sur **customer_id**, **product_id**, **date_id**). \

### ğŸ“ˆ Visualisation Power BI
Le rapport Power BI Desktop est disponible dans **reports/dataco_powerbi.pbix**. Il se connecte soit directement Ã  la base PostgreSQL **dataco_dw**, soit aux fichiers CSV de **data/processed/**.

Le rapport contient plusieurs pages thÃ©matiques :

#### 1. Ventes & profit
**KPI** : ***chiffre d'affaires total**, **profit total**, **taux de marge**.

**Graphiques** :

- Ventes dans le temps (annÃ©e / mois).
- Ventes & profit par segment client.
- Ventes par catÃ©gorie produit.
- Profit total par marchÃ©.

**Filtres** : **annÃ©e**, **catÃ©gorie**, **marchÃ©**, **mode dâ€™expÃ©dition**.

#### 2. Livraison & dÃ©lais
**KPI** : **% de commandes en retard**, **dÃ©lai moyen (jours)**, **durÃ©e dâ€™expÃ©dition rÃ©elle**.

**Graphiques** :

- DurÃ©e dâ€™expÃ©dition rÃ©elle vs prÃ©vue par annÃ©e.
- Taux de retard par marchÃ©.
- Taux de retard par mode dâ€™expÃ©dition.
- Nombre de commandes par statut de livraison.

**Filtres** : annÃ©e, marchÃ©, mode dâ€™expÃ©dition.

#### 3. Clients & segments
**KPI** : **nombre de clients**, **CA moyen par client**, **profit moyen par client**.

**Graphiques** :
- Ventes & profit par segment client.
- Ventes par pays client.
- Top 10 clients par chiffre dâ€™affaires (nom & prÃ©nom concatÃ©nÃ©s).

**Filtres** : annÃ©e, segment client, pays.

#### 4. Produits & catÃ©gories
**KPI** : **nombre de produits**, **CA moyen par produit**, **profit moyen par produit**.

**Graphiques** :
- Ventes & profit par catÃ©gorie produit.
- Ventes par dÃ©partement.
- Top 10 produits par chiffre dâ€™affaires.

**Filtres** : annÃ©e, catÃ©gorie, dÃ©partement.

Pour ouvrir le rapport :

- Lancer Power BI Desktop.

- Ouvrir reports/dataco_powerbi.pbix.

- VÃ©rifier au besoin la source de donnÃ©es via Transformer les donnÃ©es â†’ ParamÃ¨tres de la source de donnÃ©es.

## ğŸ“„ Licence

Ce projet est rÃ©alisÃ© dans un cadre acadÃ©mique (projet d'apprentissage /
portfolio). Toute rÃ©utilisation du dataset doit respecter les conditions
d'utilisation de Kaggle et de la source d'origine. \